{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_LABELS = 'C:\\Tensorflow\\models\\\\research\\object_detection\\data\\mscoco_label_map.pbtxt'\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
    "\n",
    "COCO17_HUMAN_POSE_KEYPOINTS = [(0, 1), (0, 2), (1, 3), (2, 4), (0, 5), (0, 6), (5, 7), (7, 9), (6, 8), (8, 10), (5, 6), (5, 11), (6, 12), (11, 12), (11, 13), (13, 15), (12, 14), (14, 16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "vidcap = cv2.VideoCapture('world.mp4')\n",
    "success, img = vidcap.read()\n",
    "\n",
    "video_fps = vidcap.get(cv2.CAP_PROP_FPS),\n",
    "total_frames = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "height = vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "width = vidcap.get(cv2.CAP_PROP_FRAME_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('gaze_positions.csv')\n",
    "df = df.drop_duplicates(subset = [\"world_index\"])\n",
    "df = df[['world_index', 'norm_pos_x', 'norm_pos_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_coords(x, y):\n",
    "    x = x * width\n",
    "    y = y * height\n",
    "    y = height - y\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def point_in_rect(x, y, box):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(img, detector_output, idx):\n",
    "\n",
    "  label_id_offset = 0\n",
    "  image_np_with_detections = img\n",
    "\n",
    "  # Use keypoints if available in detections\n",
    "  keypoints, keypoint_scores = None, None\n",
    "  if 'detection_keypoints' in detector_output:\n",
    "    keypoints = detector_output['detection_keypoints'][0]\n",
    "    keypoint_scores = detector_output['detection_keypoint_scores'][0]\n",
    "\n",
    "    x, y = df['world_index' == idx][['norm_pos_x', 'norm_pos_y']]\n",
    "\n",
    "    for box in detector_output['detection_boxes'][0]:\n",
    "      print(box)\n",
    "\n",
    "    if point_in_rect(x, y, box):\n",
    "      viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detector_output['detection_boxes'][0],\n",
    "            (detector_output['detection_classes'][0].numpy() + label_id_offset).astype(int),\n",
    "            detector_output['detection_scores'][0],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=5,\n",
    "            min_score_thresh=.40,\n",
    "            agnostic_mode=False,\n",
    "            keypoints=keypoints,\n",
    "            keypoint_scores=keypoint_scores,\n",
    "            keypoint_edges=COCO17_HUMAN_POSE_KEYPOINTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference___call___32344) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_97451) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_77595) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_103456) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_93843) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_107064) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_75975) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    }
   ],
   "source": [
    "detector = hub.load(\"https://tfhub.dev/tensorflow/efficientdet/d0/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "while success:   \n",
    "\n",
    "    image_tensor = tf.convert_to_tensor(img)\n",
    "    image_tensor = image_tensor[tf.newaxis, ...]\n",
    "    draw_boxes(img, detector(image_tensor), idx)\n",
    "\n",
    "    frames.append(img)  \n",
    "    success, img = vidcap.read()\n",
    "    idx += 0\n",
    "vidcap.release()\n",
    "\n",
    "del detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c03de8f6d95ffa92d0aa4dfd65a77b46c5423e187450d4fc348ec36517fd26e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf_gpu_test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
