{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('gaze_positions.csv')\n",
    "panorama = cv2.imread('panorama.png')\n",
    "\n",
    "# Initiate SIFT detector\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "MIN_MATCH_COUNT = 10\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks = 50)\n",
    "\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "kp2, des2 = sift.detectAndCompute(panorama, None)\n",
    "\n",
    "vidcap = cv2.VideoCapture('world.mp4')\n",
    "success, frame = vidcap.read()\n",
    "\n",
    "video_fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "height = int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "width = int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "df['X'] = df['norm_pos_x'] * width\n",
    "df['Y'] = height - df['norm_pos_y'] * height\n",
    "df = df[['world_index', 'X', 'Y']]\n",
    "\n",
    "df = df.astype({'world_index': int, 'X': int, 'Y': int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\features2d\\src\\draw.cpp:156: error: (-201:Incorrect size of input array) outImg has size less than need to draw img1 and img2 together in function 'cv::_prepareImgAndDrawKeypoints'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Arthur\\Desktop\\school\\StageHITlab\\MovingEyetrackHeatmap\\parse_pupil.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arthur/Desktop/school/StageHITlab/MovingEyetrackHeatmap/parse_pupil.ipynb#ch0000001?line=30'>31</a>\u001b[0m     draw_params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(matchColor \u001b[39m=\u001b[39m (\u001b[39m0\u001b[39m,\u001b[39m255\u001b[39m,\u001b[39m0\u001b[39m), \u001b[39m# draw matches in green color\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arthur/Desktop/school/StageHITlab/MovingEyetrackHeatmap/parse_pupil.ipynb#ch0000001?line=31'>32</a>\u001b[0m                 singlePointColor \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arthur/Desktop/school/StageHITlab/MovingEyetrackHeatmap/parse_pupil.ipynb#ch0000001?line=32'>33</a>\u001b[0m                 matchesMask \u001b[39m=\u001b[39m matchesMask, \u001b[39m# draw only inliers\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arthur/Desktop/school/StageHITlab/MovingEyetrackHeatmap/parse_pupil.ipynb#ch0000001?line=33'>34</a>\u001b[0m                 flags \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arthur/Desktop/school/StageHITlab/MovingEyetrackHeatmap/parse_pupil.ipynb#ch0000001?line=35'>36</a>\u001b[0m     \u001b[39m# if frame_idx == 0:\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arthur/Desktop/school/StageHITlab/MovingEyetrackHeatmap/parse_pupil.ipynb#ch0000001?line=36'>37</a>\u001b[0m     \u001b[39m#     result = cv2.drawMatches(frame, kp1, img2, kp2, good, None, **draw_params)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arthur/Desktop/school/StageHITlab/MovingEyetrackHeatmap/parse_pupil.ipynb#ch0000001?line=37'>38</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arthur/Desktop/school/StageHITlab/MovingEyetrackHeatmap/parse_pupil.ipynb#ch0000001?line=44'>45</a>\u001b[0m     \u001b[39m#     result = np.empty(result.shape)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arthur/Desktop/school/StageHITlab/MovingEyetrackHeatmap/parse_pupil.ipynb#ch0000001?line=45'>46</a>\u001b[0m     \u001b[39m#     result = cv2.drawMatches(frame, kp1, img2, kp2, good, result, **draw_params)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Arthur/Desktop/school/StageHITlab/MovingEyetrackHeatmap/parse_pupil.ipynb#ch0000001?line=47'>48</a>\u001b[0m     result \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mdrawMatches(frame, kp1, img2, kp2, good, \u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdraw_params)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arthur/Desktop/school/StageHITlab/MovingEyetrackHeatmap/parse_pupil.ipynb#ch0000001?line=49'>50</a>\u001b[0m     writer\u001b[39m.\u001b[39mwrite(result)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arthur/Desktop/school/StageHITlab/MovingEyetrackHeatmap/parse_pupil.ipynb#ch0000001?line=51'>52</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\features2d\\src\\draw.cpp:156: error: (-201:Incorrect size of input array) outImg has size less than need to draw img1 and img2 together in function 'cv::_prepareImgAndDrawKeypoints'\n"
     ]
    }
   ],
   "source": [
    "writer = cv2.VideoWriter(f\"output.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), video_fps, (width + panorama.shape[1], height))\n",
    "frame_idx = 0\n",
    "\n",
    "while success:\n",
    "\n",
    "    img2 = panorama\n",
    "\n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    kp1, des1 = sift.detectAndCompute(frame, None)\n",
    "\n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "    # store all the good matches as per Lowe's ratio test.\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    if len(good)> MIN_MATCH_COUNT:\n",
    "        src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        matchesMask = mask.ravel().tolist()\n",
    "        \n",
    "        h,w,c = frame.shape\n",
    "        pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "        dst = cv2.perspectiveTransform(pts, M)\n",
    "        img2 = cv2.polylines(img2, [np.int32(dst)], True, 255, 3, cv2.LINE_AA)\n",
    "\n",
    "        draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "                    singlePointColor = None,\n",
    "                    matchesMask = matchesMask, # draw only inliers\n",
    "                    flags = 3)\n",
    "        \n",
    "        # if frame_idx == 0:\n",
    "        #     result = cv2.drawMatches(frame, kp1, img2, kp2, good, None, **draw_params)\n",
    "\n",
    "        # else:\n",
    "        #     draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "        #     singlePointColor = None,\n",
    "        #     matchesMask = matchesMask, # draw only inliers\n",
    "        #     flags = 3)\n",
    "\n",
    "        #     result = np.empty(result.shape)\n",
    "        #     result = cv2.drawMatches(frame, kp1, img2, kp2, good, result, **draw_params)\n",
    "\n",
    "        result = cv2.drawMatches(frame, kp1, img2, kp2, good, None, **draw_params)\n",
    "\n",
    "        writer.write(result)\n",
    "\n",
    "    else:\n",
    "        matchesMask = None\n",
    "\n",
    "\n",
    "\n",
    "    success, frame = vidcap.read()\n",
    "    frame_idx += 1\n",
    "\n",
    "    print(f\"\\rDone {round((frame_idx / total_frames) * 100)}%\", end='')\n",
    "\n",
    "writer.release()\n",
    "vidcap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS + cv2.DRAW_MATCHES_FLAGS_DRAW_OVER_OUTIMG"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "59f46f3a3121fd582e20dd4d1e3a01837a6af6a9d4882bf236221b9e3ca28403"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('movingEyetrackerHeatmap': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
